# Thoughts on Learning

I'm just having a think about the process that we seem to be landing on for training AI models, and how it mimics my own learning process. I wonder if it's a fundamental property of how neural network-like systems learn. The basic procedure is:

1. Mimic the task. It's all I can do, and it's all the fresh model can do, since neither of us have the prior knowledge to even know how to reason about the task. So we start by imitating an expert, who has the knowledge and skill to perform the task well. This can be unsupervised learning and/or supervised learning, ie pretraining and finetuning.
2. Once you have some experience, you have the words and framing in which to imagine and reason about the task, and to think up ways to perform it better. Without this prior knowledge, you can't even formulate the problem. This is akin to various "chain-of-thought" and "reasoning" techniques in LLMs, especially during the actual training, where the model is literally learning from feedback it receives on its reasoning and/or answer. This is where we all integrate new knowledge and skills into our existing mental models, and learn to apply them in practice to previously unseen situations.
3. Continual learning. Humans have managed to figure this out to some degree, and we've explored the limitations of it in various disciplines. For ML, it's still an unsolved problem, but tbh it feels like an engineering problem rn. The real problem isn't that the models don't have human-like continual learning abilities, for the most part - it's that we think that *we* have better abilities than we do, and that we - reasonably, i think - expect that we can make models that do it perfectly. That's just where we are with our knowledge rn, and time and compute and coffee will likely solve it. It's possible that it's just a matter of continually refining datasets and models, and the things we teach them. That includes a lot of data though, iof you think about it. so we're probably at the stage where we've bootstrapped language models and now we're using them and vision-language models and stuf to bootstrap the rest. as above, so below - it's all markov, all the way down.

Possibly one of the things we need to figure out is where everything fits in the hierarchy. you can think of a dataset - language, even - as a program. In fact a dataset is a set of pragrams. all the programs run on the substrate of the model, but not all tasks are on the same level of abstraction. we need to figure out which tasks need to be built in to the arcvhitecture as priors, and which need to be learned by the model. you can't just do it arbitrarily, because the wrong architectural priors will get in the way of learning instead of helping it.
